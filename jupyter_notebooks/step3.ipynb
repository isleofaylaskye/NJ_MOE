{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define input and output file paths\n",
    "path = os.path.join(os.path.dirname(os.getcwd()))\n",
    "path='/Users/ayla/workflow'\n",
    "ipath = os.path.join(path,'data')\n",
    "opath = os.path.join(path,'data')\n",
    "input_file_dir=os.path.join(ipath)\n",
    "output_file_dir=os.path.join(opath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ipath and opath are identical. This is because this script uses one file called \"data\" for all inputs and outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Clean the Data\n",
    "The VRE table will include some BGs that have zero population. We must remove these zero population BGs from our csv file. \n",
    "\n",
    "Before we do this, we should identify the number of BGs that have a non-zero population but have zero population 2.0 times the poverty line (this implies that the entire population is low income).\n",
    "We donâ€™t want to accidentally delete BGs that are 100% low income. The script below identifies 100% low income BGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 100% low income block groups\n",
      "11.0\n",
      "                      GEOID  ORDER  ESTIMATE  Var_Rep1  Var_Rep2\n",
      "3260  1500000US340076105001      1       147       109       135\n",
      "3261  1500000US340076105001      8         0         0         0\n",
      "3326  1500000US340076115003      1        78        99        79\n",
      "3327  1500000US340076115003      8         0         0         0\n",
      "5104  1500000US340139801001      1         4         4         4\n",
      "5105  1500000US340139801001      8         0         0         0\n",
      "5138  1500000US340155002043      1        54        40        48\n",
      "5139  1500000US340155002043      8         0         0         0\n",
      "5496  1500000US340155020026      1        11        10         1\n",
      "5497  1500000US340155020026      8         0         0         0\n",
      "5522  1500000US340155024001      1         4        15         0\n",
      "5523  1500000US340155024001      8         0         0         0\n",
      "5846  1500000US340170067002      1       160       157       214\n",
      "5847  1500000US340170067002      8         0         0         0\n",
      "6660  1500000US340210004002      1       395       213       514\n",
      "6661  1500000US340210004002      8         0         0         0\n",
      "6722  1500000US340210013001      1       294       292       303\n",
      "6723  1500000US340210013001      8         0         0         0\n",
      "6984  1500000US340210037072      1        14         5        14\n",
      "6985  1500000US340210037072      8         0         0         0\n",
      "7166  1500000US340210045011      1        54        53        53\n",
      "7167  1500000US340210045011      8         0         0         0\n"
     ]
    }
   ],
   "source": [
    "#Identifies row pairs for which both order = 8 has a corresponding estimate that equals zero (indicating zero population 2.0 times poverty line) \n",
    "#AND order = 1 has a non-zero estimate (has a total population)\n",
    "#If a row pair meets these requirements, it means it is a 100% low income block group\n",
    "import pandas as pd\n",
    "#'/Users/ayla/workflow/data/edited_VRE_complete_NJ.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = f\"{ipath}/{'edited_VRE_complete_NJ.csv'}\"  # Replace with your CSV file name\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "# Initialize a list to store the identified pairs\n",
    "identified_pairs = []\n",
    "\n",
    "# Iterate over the dataframe, processing each pair of rows\n",
    "for i in range(1, data.shape[0], 2):\n",
    "    if data.iloc[i-1, 1] == 1 and data.iloc[i, 1] == 8 and data.iloc[i-1, 0] == data.iloc[i, 0]:\n",
    "        # Extract the GEOID for the current pair\n",
    "        geoid = data.iloc[i-1, 0]\n",
    "        \n",
    "        # Extract the estimates for the current pair\n",
    "        estimate_order_1 = data.iloc[i-1]['ESTIMATE']\n",
    "        estimate_order_8 = data.iloc[i]['ESTIMATE']\n",
    "        \n",
    "        # Check if ORDER = 8 estimate is zero and ORDER = 1 estimate is non-zero\n",
    "        if estimate_order_8 == 0 and estimate_order_1 != 0:\n",
    "            # Append the rows to the identified_pairs list\n",
    "            identified_pairs.append(data.iloc[i-1, :5])\n",
    "            identified_pairs.append(data.iloc[i, :5])\n",
    "\n",
    "# Convert the list of identified pairs to a DataFrame for easier visualization\n",
    "all_low_income_bg_df = pd.DataFrame(identified_pairs)\n",
    "\n",
    "#define df as data frame of identified pairs only\n",
    "df = pd.DataFrame(identified_pairs)\n",
    "\n",
    "#Print number of identified pairs\n",
    "num_rows = df.shape[0]\n",
    "print(\"Number of 100% low income block groups\")\n",
    "#print \"num_rows\" divided by two since each pair of rows represents 1 block group\n",
    "print(num_rows/2)\n",
    "#store this value for later \n",
    "num_all_low_income = (num_rows/2)\n",
    "# Print the identified pairs\n",
    "print(all_low_income_bg_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the BGs that have zero total population. We know logically that these BGs should also contain zero individuals 2.0 times the poverty line. \n",
    "\n",
    "However, we must test this assumption to ensure the accuracy and validity of our data. In order to perform this test, run the following script that tests for BG pairs in which total population is zero but percent 2.0 times the poverty line is non-zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row pairs for which total population estimate is zero and population > 2.0 poverty line estimate is non-zero:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#order = 1 (total population) has an estimate that equals zero, but order = 8 (population > 2.0 times the poverty line) has a non-zero estimate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (same input file as previous code box)\n",
    "input_file = f\"{ipath}/{'edited_VRE_complete_NJ.csv'}\"  # Replace with your CSV file name\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize a list to store the identified pairs\n",
    "identified_pairs = []\n",
    "\n",
    "# Iterate over the dataframe, processing each pair of rows\n",
    "for i in range(1, data.shape[0], 2):\n",
    "    if data.iloc[i-1, 1] == 1 and data.iloc[i, 1] == 8 and data.iloc[i-1, 0] == data.iloc[i, 0]:\n",
    "        # Extract the GEOID for the current pair\n",
    "        geoid = data.iloc[i-1, 0]\n",
    "        \n",
    "        # Extract the estimates for the current pair\n",
    "        estimate_order_1 = data.iloc[i-1]['ESTIMATE']\n",
    "        estimate_order_8 = data.iloc[i]['ESTIMATE']\n",
    "        \n",
    "        # Check if ORDER = 1 estimate is zero and ORDER = 8 estimate is non-zero\n",
    "        if estimate_order_1 == 0 and estimate_order_8 != 0:\n",
    "            # Append the rows to the identified_pairs list\n",
    "            identified_pairs.append(data.iloc[i-1, :5])\n",
    "            identified_pairs.append(data.iloc[i, :5])\n",
    "\n",
    "# Convert the list of identified pairs to a DataFrame for easier visualization\n",
    "zero_pop_nonzero_est_df = pd.DataFrame(identified_pairs)\n",
    "\n",
    "# Print the identified pairs\n",
    "print(\"Row pairs for which total population estimate is zero and population > 2.0 poverty line estimate is non-zero:\")\n",
    "print(zero_pop_nonzero_est_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script should return an empty data frame. This indicates that there are no row pairs for which BG pairs in which total population is zero but percent 2.0 times the poverty line is non-zero. If it is not empty, ensure that the correct file is being used as the input file. If it is empty, please continue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now remove all of the zero population BGs from our csv file. Let's start by printing them and saving them to a seperate csv file called \"deleted_zero_pop_bgs.csv\" in case we want to reference them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero population block groups\n",
      "90\n",
      "                       GEOID  ORDER  ESTIMATE  Var_Rep1  Var_Rep2\n",
      "386    1500000US340019900000      1         0         0         0\n",
      "387    1500000US340019900000      8         0         0         0\n",
      "1974   1500000US340057001043      1         0         0         0\n",
      "1975   1500000US340057001043      8         0         0         0\n",
      "1986   1500000US340057003034      1         0         0         0\n",
      "...                      ...    ...       ...       ...       ...\n",
      "10725  1500000US340299801001      8         0         0         0\n",
      "10726  1500000US340299900000      1         0         0         0\n",
      "10727  1500000US340299900000      8         0         0         0\n",
      "11576  1500000US340339900000      1         0         0         0\n",
      "11577  1500000US340339900000      8         0         0         0\n",
      "\n",
      "[180 rows x 5 columns]\n",
      "Results have been written to /Users/ayla/workflow/data/deleted_zero_pop_bgs.csv\n"
     ]
    }
   ],
   "source": [
    "#order = 1 (total population) has an estimate that equals zero, AND order = 8 (population > 2.0 times the poverty line) estimate equals zero\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (same input file as previous code box)\n",
    "input_file = f\"{ipath}/{'edited_VRE_complete_NJ.csv'}\"  # Replace with your CSV file name\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize a list to store the identified pairs\n",
    "identified_pairs = []\n",
    "\n",
    "# Iterate over the dataframe, processing each pair of rows\n",
    "for i in range(1, data.shape[0], 2):\n",
    "    if data.iloc[i-1, 1] == 1 and data.iloc[i, 1] == 8 and data.iloc[i-1, 0] == data.iloc[i, 0]:\n",
    "        # Extract the GEOID for the current pair\n",
    "        geoid = data.iloc[i-1, 0]\n",
    "        \n",
    "        # Extract the estimates for the current pair\n",
    "        estimate_order_1 = data.iloc[i-1]['ESTIMATE']\n",
    "        estimate_order_8 = data.iloc[i]['ESTIMATE']\n",
    "        \n",
    "        # Check if both ORDER = 1 and ORDER = 8 estimates are zero\n",
    "        if estimate_order_1 == 0 and estimate_order_8 == 0:\n",
    "            # Append the rows to the identified_pairs list\n",
    "            identified_pairs.append(data.iloc[i-1, :5])\n",
    "            identified_pairs.append(data.iloc[i, :5])\n",
    "\n",
    "# Convert the list of identified pairs to a DataFrame for easier visualization\n",
    "zero_pop_df = pd.DataFrame(identified_pairs)\n",
    "\n",
    "# Define df as data frame of identified pairs only\n",
    "df = zero_pop_df\n",
    "\n",
    "# Print number of identified pairs\n",
    "num_rows = df.shape[0]\n",
    "print(\"Number of zero population block groups\")\n",
    "\n",
    "# Print \"num_rows\" divided by two since each pair of rows represents 1 block group\n",
    "print(num_rows // 2)\n",
    "\n",
    "# Store this value for later use\n",
    "num_zero_pop = num_rows // 2\n",
    "\n",
    "# Print the identified pairs\n",
    "print(zero_pop_df)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = f\"{opath}/deleted_zero_pop_bgs.csv\"\n",
    "\n",
    "# Write the identified pairs to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now let's actually remove all of the zero population BGs from our csv file. The output of the following script is a new csv file titled \"filtered_complete_NJ.csv\" that contains all of the original BGs except for the zero population BGs identified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results have been written to /Users/ayla/workflow/data/filtered_complete_NJ.csv\n"
     ]
    }
   ],
   "source": [
    "#Create new csv file without zero pop BGs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (same input file as previous code box)\n",
    "input_file = f\"{ipath}/{'edited_VRE_complete_NJ.csv'}\"  # Replace with your CSV file name\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Initialize a list to store the indices of the identified pairs\n",
    "indices_to_remove = []\n",
    "\n",
    "# Iterate over the dataframe, processing each pair of rows\n",
    "for i in range(1, data.shape[0], 2):\n",
    "    if data.iloc[i-1, 1] == 1 and data.iloc[i, 1] == 8 and data.iloc[i-1, 0] == data.iloc[i, 0]:\n",
    "        # Extract the estimates for the current pair\n",
    "        estimate_order_1 = data.iloc[i-1]['ESTIMATE']\n",
    "        estimate_order_8 = data.iloc[i]['ESTIMATE']\n",
    "        \n",
    "        # Check if both ORDER = 1 and ORDER = 8 estimates are zero\n",
    "        if estimate_order_1 == 0 and estimate_order_8 == 0:\n",
    "            # Append the indices to the indices_to_remove list\n",
    "            indices_to_remove.append(i-1)\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "# Drop the identified pairs from the DataFrame\n",
    "filtered_data = data.drop(indices_to_remove)\n",
    "\n",
    "# Define the output file path\n",
    "output_file = f\"{opath}/filtered_complete_NJ.csv\"\n",
    "\n",
    "# Write the filtered DataFrame to a new CSV file\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered results have been written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
